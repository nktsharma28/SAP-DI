{
	"properties": {},
	"description": "ML_DEMAND_SENSING_1",
	"processes": {
		"testscript1": {
			"component": "test_script",
			"metadata": {
				"label": "test script",
				"x": 577.9999961853027,
				"y": 80,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {
					"script": "from operators.test_script.function import foo\n\nimport pandas as pd\nimport io\nimport datetime\nimport pickle\n\nfrom functools import partial\n\nimport multiprocessing\nfrom multiprocessing import get_context, cpu_count, Pool\n\n\ndef on_input(msg1, msg2):\n#def gen():\n    \n    GROUPBY_LEVEL = ['retailer', 'state', 'brand', 'ppg']\n    TARGET = \"FillMean\"\n    DATE_COLUMN = \"week_ending_date\"\n    # Add additional regressors to the forecast\n    ADDITIONAL_REGRESSORS = ['food_cpi_nat_mth', 'snap_cost_st_mth']\n    REGRESSOR_LAG = {'snap_cost_st_mth': 1}\n    \n    # Keep track of data throughout run\n    data = []\n    excluded = []\n    df_final_out = pd.DataFrame()\n    count=0\n    try_count = 0\n\n    # Establish training/test windows\n    TRAIN_START = pd.to_datetime('2019-01-01').date()\n    TRAIN_END = pd.to_datetime('2020-06-30').date()\n    TEST_START = pd.to_datetime('2020-09-30').date()\n    TEST_END = pd.to_datetime('2020-12-31').date()\n    # To speed up running, set to desired sample size if not set to 0\n    SAMPLE = 0\n    # Set logistic growth function cap\n    CAP_PERCENTILE = 95\n    # Future Period\n    FUTURE_PERIOD = 25\n    # model parameters\n    OPTIM_PARAM = {\"growth\": \"logistic\", \"seasonality_prior_scale\": 0.1}\n    \n\n    def custom_fillna(series):\n        if series.dtype is pd.np.dtype(float):\n            return series.fillna(0)\n        elif series.dtype is pd.np.dtype('int32'):\n            return series.fillna(0)\n        elif series.dtype is pd.np.dtype('int64'):\n            return series.fillna(0)\n        elif series.dtype is pd.np.dtype(str):\n            return series.fillna(0)  \n        elif series.dtype is pd.np.dtype(object):\n            return series.fillna('')  \n        else:\n            return series\n\n    \n    # Obtain data\n    # input table from SEP_COVIDEXT.Z_SEP.AnalyticalModels.SCM.DemandForecasting.CovidExternal::TA_SCM_COVID_FULL_SAMPLE_TRAIN\n    # format data frame as per data type in source table\n    \n    #df_sample_train = pd.read_csv(io.StringIO(msg1.body), sep=\",\")\n    df =  pd.read_json(io.StringIO(msg1))\n    #df =  pd.read_csv('/vrep/vflow/scm_demand_sensing_masked_data_imputed_v5.csv')\n    df = df[['week_ending_date', 'retailer', 'state', 'business', 'category', 'brand', 'ppg', 'pos_qty_ty', 'pos_dollar_ty', 'FillMean']]\n    \n    # break according to api.multiplicity and api.multiplicity_index\n    batch_size = int(df.shape[0]/api.multiplicity)\n    begin_batch = api.multiplicity_index*batch_size\n    end_batch = (api.multiplicity_index+1)*batch_size\n    \n    df = df.iloc[begin_batch:end_batch]\n    \n    #checking null values and replace accordingly\n    df = df.apply(custom_fillna)\n    df['week_ending_date'] =  df['week_ending_date'].astype(str)\n    \n    #checking null values and replace accordingly\n    df_add_external =  pd.read_json(io.StringIO(msg2))\n    #df_add_external =  pd.read_csv('/vrep/vflow/external_merged_weekly_modeling_source.csv')\n    df_add_external = df_add_external[['date', 'state', 'state_initial', 'AT_adj', 'food_cpi_nat_mth', 'snap_cost_st_mth', 'allbed_mean', 'confirmed_infections', 'deaths_mean', 'est_infections_mean', 'mobility_composite_wors', 'states_on_stay_home', 'states_on_travel_limit', 'states_on_any_business', 'states_on_all_non-ess_business', 'states_on_any_gathering_restrict', 'states_on_educational_fac']] \n    \n    api.send('output', str(df.shape))\n    df_add_external = df_add_external.apply(custom_fillna)\n    df_add_external['date'] =  df_add_external['date'].astype(str)\n  \n    def get_end_date_from_week(year,week,day):\n\n        #Calculates first day and last day of week, given a year and week\n        first_day = datetime.datetime.strptime(f'{year}-W{int(week )- 1}-1', '%Y-W%W-%w').date()\n        last_day = first_day + datetime.timedelta(days=day)\n        return last_day\n    \n    def get_week_number_from_end_date(date_obj):\n        #Calculates week number in year given a date.\n        week_number = date_obj.isocalendar()[1]\n        return week_number   \n    \n    def data_imputation(df):\n        # Fill in missing week numbers\n        df['week_of_year'] = df[DATE_COLUMN].apply(lambda x: get_week_number_from_end_date(x))\n        df[DATE_COLUMN] = pd.to_datetime(df[DATE_COLUMN]).dt.date\n        grouped = df.groupby(GROUPBY_LEVEL)\n        data1 =  grouped.values.tolist()\n\n        subset_list = []\n        for name, group in grouped:\n            subset_df = group.copy()\n            subset_df = subset_df.set_index(DATE_COLUMN)\n            # Imputation approach using mean value\n            subset_df = subset_df.assign(imputed_qty=subset_df[TARGET].fillna(subset_df[TARGET].mean()))\n            subset_df = subset_df.reset_index()\n            subset_list.append(subset_df)\n        imputed_df = pd.concat(subset_list)\n        #imputed_df.to_csv(DATA_PATH+'processed/imputed_data.csv', index=False)\n        return imputed_df\n\n    def add_external_data(df, df_add):\n        #Takes client data and external data\n        \n\n        df_add = df_add[['date', 'state_initial'] + ADDITIONAL_REGRESSORS]\n        df_add.rename(columns={'date': 'week_ending_date', 'state_initial': 'state'}, inplace=True)\n        if REGRESSOR_LAG != {}:\n            for k, v in REGRESSOR_LAG.items():\n                df_add[k] = df_add.groupby('state')[k].shift(v)\n        df = pd.merge(df, df_add, on=['week_ending_date', 'state'], how='left')\n        df_add[DATE_COLUMN] = pd.to_datetime(df_add[DATE_COLUMN]).dt.date\n        df_add.rename(columns={DATE_COLUMN: 'ds'}, inplace=True)\n        return df, df_add\n\n    def select_data(df):\n        if ADDITIONAL_REGRESSORS:\n            df = df[[DATE_COLUMN] + GROUPBY_LEVEL + ADDITIONAL_REGRESSORS + [TARGET]]\n        else:\n            df = df[[DATE_COLUMN] + GROUPBY_LEVEL + [TARGET]]\n        print('Selected data columns.')\n\n        return df\n\n    def select_sample(df):\n        df_sum = df.groupby(GROUPBY_LEVEL)[[TARGET]].sum().reset_index().rename(columns={TARGET: 'total_qty'})\n        top_100 = df_sum.nlargest(columns='total_qty', n=SAMPLE)\n        top_100 = top_100.drop(['total_qty'], axis=1)\n        df = pd.merge(top_100, df, how='inner', on=GROUPBY_LEVEL)\n        print('Chose top {} samples.'.format(SAMPLE))\n        return df\n    \n    def load_holiday_calendar():\n        # Builds a holiday calendar.\n        # New year's day\n        newyear = pd.DataFrame({\n        'holiday': 'newyear',\n        'ds': pd.to_datetime(['2019-01-01','2020-01-01']),\n        })\n        # Martin Luther King Jr. Day\n        MLK_day = pd.DataFrame({\n        'holiday': 'MLK_day',\n        'ds': pd.to_datetime(['2019-01-21','2020-01-20']),\n        })\n        # March Madness\n        march_madness = pd.DataFrame({\n        'holiday': 'march_madness',\n        'ds': pd.to_datetime(['2018-03-24','2018-03-31','2019-03-30','2019-04-06','2020-03-28','2020-04-04', '2021-03-27','2021-04-03']),\n        })\n        # Superbowl\n        superbowls = pd.DataFrame({\n        'holiday': 'superbowl',\n        'ds': pd.to_datetime(['2018-01-27','2018-02-03', '2019-01-26','2019-02-02', '2020-01-25','2020-02-01','2021-01-30','2021-02-06']),\n        })\n        # Lent\n        lent = pd.DataFrame({\n        'holiday': 'lent',\n        'ds': pd.to_datetime(['2018-02-17', '2018-02-24','2018-03-03','2018-03-10','2018-03-17','2018-03-24',\n                            '2019-03-09', '2019-03-16','2019-03-23','2019-03-30','2019-04-06','2019-04-13',\n                            '2020-02-29', '2020-03-07', '2020-03-14','2020-03-21','2020-03-28','2020-04-04',\n                            '2021-02-20', '2021-02-27', '2021-03-06','2021-03-13','2021-03-20','2021-03-27']),\n        })\n        # Easter (Wednesday â€“ Easter Friday)\n        easter = pd.DataFrame({\n        'holiday': 'easter',\n        'ds': pd.to_datetime(['2018-03-31', '2019-04-20', '2020-04-11','2021-04-03']),\n        })\n        # Memorial day\n        memorial_day = pd.DataFrame({\n        'holiday': 'memorial_day',\n        'ds': pd.to_datetime(['2019-05-27', '2020-05-25']),\n        })\n        # Independence day\n        indep_day = pd.DataFrame({\n        'holiday': 'indep_day',\n        'ds': pd.to_datetime(['2019-07-04', '2020-07-03']),\n        })\n        # Labor day\n        labor_day = pd.DataFrame({\n        'holiday': 'indep_day',\n        'ds': pd.to_datetime(['2019-09-02', '2020-09-07']),\n        })\n        # Halloween\n        halloween = pd.DataFrame({\n        'holiday': 'halloween',\n        'ds': pd.to_datetime(['2018-10-27', '2019-10-26', '2020-10-31','2021-10-30']),\n        })\n        # Veteran's day\n        veteran_day = pd.DataFrame({\n        'holiday': 'veteran_day',\n        'ds': pd.to_datetime(['2019-11-11', '2020-11-11']),\n        })\n        # Thanksgiving\n        thanksgiving = pd.DataFrame({\n        'holiday': 'thanksgiving',\n        'ds': pd.to_datetime(['2019-11-28', '2020-11-26']),\n        })\n        # Christmas\n        Christmas = pd.DataFrame({\n        'holiday': 'thanksgiving',\n        'ds': pd.to_datetime(['2019-12-25', '2020-12-25']),\n        })\n\n        holidays_df = pd.concat((newyear, MLK_day, march_madness, superbowls, lent, easter, memorial_day, indep_day, labor_day, halloween, veteran_day, thanksgiving, Christmas))\n        return holidays_df\n\n    def get_week_day(df):\n        df['ds'] = pd.to_datetime(df['ds']).dt.date\n        return df['ds'].iloc[0].weekday()\n\n    def custom_holidays(week_day):\n        custom_holidays = load_holiday_calendar()\n        custom_holidays['week_no'] = custom_holidays['ds'].apply(lambda x: get_week_number_from_end_date(x))\n        custom_holidays['year'] = custom_holidays['ds'].apply(lambda x: int(x.strftime('%Y')))\n        custom_holidays['week_ending_date'] = custom_holidays.apply(\n            lambda x: get_end_date_from_week(x['year'], x['week_no'], week_day), 1)\n        custom_holidays.rename(columns={'ds': 'date', 'week_ending_date': 'ds'}, inplace=True)\n        custom_holidays = custom_holidays[['ds', 'holiday']]\n\n        return custom_holidays\n\n    # def plot_mape(stats_df):\n    #     plt.style.use('ggplot')\n    #     first_edge, last_edge = stats_df['mape'].min(), stats_df['mape'].max()\n\n    #     n_equal_bins = 60\n    #     bin_edges = np.linspace(start=first_edge, stop=last_edge, num=n_equal_bins + 1, endpoint=True)\n\n    #     # Creating histogram\n    #     fig, ax = plt.subplots(figsize =(8, 4))\n    #     ax.hist(stats_df['mape'], bins = bin_edges,  color = (0.5,0.1,0.5,0.6))\n\n    #     plt.title('MAPE distribution of forecast results.')\n\n    #     # Save plot\n    #     plt.savefig(DATA_PATH+'mape_plot.png')\n\n    def mean_absolute_percentage_error(y_true, y_pred):\n        y_true, y_pred = np.array(y_true), np.array(y_pred)\n        return np.mean(np.abs((y_true - y_pred)/ y_true)) * 100\n    \n\n    df, df_add_new = add_external_data(df, df_add_external)\n    df_add_new['ds'] =  df_add_new['ds'].astype(str)\n    #data =  df.values.tolist()\n\n    # Track how long end-to-end modeling takes\n    #load data, date should be in first column\n    df[DATE_COLUMN] = pd.to_datetime(df[DATE_COLUMN]).dt.date\n    df[DATE_COLUMN] =  df[DATE_COLUMN].astype(str) #Convert Date to String for DI\n    # Load Additional Data\n    \n    # Get relevant columns\n    df = select_data(df)\n    #data =  df.values.tolist()\n\n    #get sample, if number provided, else run on full set\n    if SAMPLE:\n        df = select_sample(df)\n    df.rename(columns={DATE_COLUMN: 'ds', TARGET: 'y'}, inplace=True)\n\n    #get Weekday\n    week_day = get_week_day(df)\n    #create custom holiday\n    cust_df_new = custom_holidays(week_day)\n    cust_df_new['ds'] =  cust_df_new['ds'].astype(str)\n    \n\n    df_add_new['ds'] =  df_add_new['ds'].astype(str)\n    \n    #train, forecast, and get results\n    final_data = []\n    excluded_groups = []\n    # Rename to prophet's requirements\n    df.rename(columns={DATE_COLUMN: 'ds', TARGET: 'y'}, inplace=True)\n    # Group data to build individual models at each level\n    #grouped= pd.DataFrame()#Force grouped to a dataframe\n    #grouped1= pd.DataFrame()\n    grouped = df.groupby(GROUPBY_LEVEL) #To check if groupby() is working\n    grouped_ak = df.groupby(GROUPBY_LEVEL).count() #by AK\n    data = grouped_ak.values.tolist()\n\n    data2 = grouped_ak.values.tolist()\n\n    count=0\n    lst=[]\n    api.send('output', str(len(grouped.groups)))\n    \n    pool = multiprocessing.Pool(processes=8)\n    with get_context(\"spawn\").Pool() as pool:\n        res = pool.map(partial(foo, grouped=grouped, cust_df_new=cust_df_new, df_add_new=df_add_new), list(grouped.groups.keys()), chunksize=435)\n        pool.close()\n        pool.join()\n    api.send('output', 'LINE313')    \n    api.send('output', str(res))\n    joined_df = pd.concat(res)\n    joined_df.reset_index(inplace=True)\n    api.send('output', str(joined_df.shape))\n    df1 = joined_df[['retailer', 'state', 'brand', 'ppg', 'food_cpi_nat_mth', 'snap_cost_st_mth', 'week_ending_date','FillMean']].copy()\n    #api.send(\"output\",str(joined_df.dtypes))\n    api.send('output3', df1.to_csv())\n    \"\"\"\n    f2 = '{},{},{},{},{},{},{},{},{}'# format Output_Seg\n    data=joined_df.values.tolist()\n    for j in data:\n        api.send(\"output3\",f2.format(*j)+'\\n')\n    \"\"\"\n    api.send('output2', api.Message(joined_df.to_json()))\n        \n#api.add_generator(gen)\n\napi.set_port_callback([\"input1\",\"input2\"], on_input)\n    \n"
				},
				"additionaloutports": [
					{
						"name": "output3",
						"type": "message"
					}
				]
			}
		},
		"terminal1": {
			"component": "com.sap.util.terminal",
			"metadata": {
				"label": "Terminal",
				"x": 838.9999942779541,
				"y": 12,
				"height": 80,
				"width": 120,
				"ui": "dynpath",
				"config": {}
			}
		},
		"python3operator1": {
			"component": "com.sap.system.python3Operator",
			"metadata": {
				"label": "Python3 Operator",
				"x": 838.9999942779541,
				"y": 132,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {
					"script": "import pandas as pd\nimport pickle\n\ndf_final_out = pd.DataFrame()\ncounter = 0\n\ndef on_input(data):\n    global counter\n    global df_final_out\n    partial_df = pd.read_json(data.body)\n    \n    if partial_df.shape[0] > 0:\n        df_final_out = df_final_out.append(partial_df)\n\n    counter += 1\n    if counter == 10:\n        api.send(\"output\", str(df_final_out.shape))\n\napi.set_port_callback(\"input\", on_input)\n\n\n# # Basic Example 2: Count inputs so far and send on output port (port type int64)\n# # When using the snippet below make sure you create an output port of type int64\n# counter = 0\n#\n# def on_input(data):\n#     global counter\n#     counter += 1\n#     api.send(\"output\", counter)\n#\n# api.set_port_callback(\"input\", on_input)\n\n\n# # Basic Example 3: Identity operator.\n# # When using the snippet below make sure you create input and output ports of the same type.\n# def on_input(data):\n#     api.send(\"output\", data)\n#\n# api.set_port_callback(\"input\", on_input)\n\n\n# # Basic Example 4: Sum both inputs and output result.\n# # When using the snippet below make sure you create input and output ports of the same type and\n# # that the corresponding python types can be added with the `+` operator. Example of valid\n# # port types for this snippet are: string, int64, and float64.\n# def on_input(data1, data2):\n#     api.send(\"output\", data1 + data2)\n#\n# api.set_port_callback([\"input1\", \"input2\"], on_input)\n\n\n# # Generators\n# # When using the snippet below make sure you create an output port of type int64\n# counter = 0\n#\n# def gen():\n#     global counter\n#     for i in range(0, 3):\n#         api.send(\"output\", counter)\n#         counter += 1\n#\n# api.add_generator(gen)\n# api.add_generator(gen)  # Adding the generator twice will make the function be executed twice.\n\n\n# # Timer\n# # When using the snippet below make sure you create an output port of type int64\n# counter = 0\n#\n# def t1():\n#     global counter\n#     api.send(\"output\", counter)\n#     counter += 1\n#\n# api.add_timer(\"1s\", t1)\n\n# # Timer\n# # When using the snippet below make sure you create an output port of type string\n# counter = 0\n#\n# def t2():\n#     global counter\n#     api.send(\"output\", str(counter))\n#     counter += 1\n#\n# api.add_timer(\"1s\", t2)\n\n\n# # Shutdown\n# counter = 0\n#\n# def on_input(data):\n#     global counter\n#     counter += 1\n#\n# api.set_port_callback(\"input\", on_input)\n#\n# def shutdown1():\n#     print(\"shutdown1: %d\" % counter)\n#\n# def shutdown2():\n#     print(\"shutdown2: %d\" % counter)\n#\n# api.add_shutdown_handler(shutdown1)\n# api.add_shutdown_handler(shutdown2)\n"
				},
				"additionalinports": [
					{
						"name": "input",
						"type": "message"
					}
				],
				"additionaloutports": [
					{
						"name": "output",
						"type": "string"
					}
				]
			}
		},
		"graphterminator1": {
			"component": "com.sap.util.graphTerminator",
			"metadata": {
				"label": "Graph Terminator",
				"x": 1023.9999933242798,
				"y": 72,
				"height": 80,
				"width": 120,
				"config": {}
			}
		},
		"constantgenerator111": {
			"component": "com.sap.util.constantGenerator",
			"metadata": {
				"label": "Constant Generator",
				"x": 17,
				"y": 12,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {
					"content": "SELECT  \"week_ending_date\", \"retailer\", \"state\", \"business\", \"category\", \"brand\", \"ppg\", \"week_of_year\", \"pos_qty_ty\", \"pos_dollar_ty\", \"FillMean\"  FROM      \"SEP_COVIDEXT\".\"Z_SEP.AnalyticalModels.SCM.DemandForecasting.CovidExternal::TA_SCM_COVID_FULL_SAMPLE_TRAIN\"   where  \"state\" in ('AK','AR','AZ','CA','CO','CT','DC','DE','FL','GA','HI','IA','ID')",
					"counter": 0
				}
			},
			"name": "constantgenerator11"
		},
		"saphanaclient111": {
			"component": "com.sap.hana.client2",
			"metadata": {
				"label": "FULL_SAMPLE",
				"x": 201.99999904632568,
				"y": 12,
				"height": 80,
				"width": 120,
				"config": {
					"connection": {
						"configurationType": "Configuration Manager",
						"connectionID": "HANA"
					},
					"tableName": "\"SEP_COVIDEXT\".\"Z_SEP.AnalyticalModels.SCM.DemandForecasting.CovidExternal::TA_SCM_COVID_FULL_SAMPLE_TRAIN\"",
					"csvHeader": "Ignore",
					"tableColumns": [
						{
							"name": "\"week_ending_date\"",
							"type": "DATE"
						},
						{
							"name": "\"retailer\"",
							"type": "NVARCHAR",
							"size": 100
						},
						{
							"name": "\"state\"",
							"type": "NVARCHAR",
							"size": 50
						},
						{
							"name": "\"business\"",
							"type": "NVARCHAR",
							"size": 100
						},
						{
							"name": "\"category\"",
							"type": "NVARCHAR",
							"size": 50
						},
						{
							"name": "\"brand\"",
							"type": "NVARCHAR",
							"size": 100
						},
						{
							"name": "\"ppg\"",
							"type": "NVARCHAR",
							"size": 100
						},
						{
							"name": "\"week_of_year\"",
							"type": "INTEGER"
						},
						{
							"name": "\"pos_qty_ty\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"pos_dollar_ty\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"FillMean\"",
							"type": "DOUBLE"
						}
					],
					"networkBatchSize": 5000,
					"connectionTimeoutInMs": 50000
				}
			},
			"name": "saphanaclient11"
		},
		"tostringconverter11": {
			"component": "com.sap.util.toStringConverter",
			"metadata": {
				"label": "ToString Converter",
				"x": 386.99999809265137,
				"y": 42,
				"height": 50,
				"width": 50,
				"config": {}
			},
			"name": "tostringconverter1"
		},
		"constantgenerator1111": {
			"component": "com.sap.util.constantGenerator",
			"metadata": {
				"label": "Constant Generator",
				"x": 17,
				"y": 132,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {
					"content": " select * from \"SEP_COVIDEXT\".\"Z_SEP.AnalyticalModels.SCM.DemandForecasting.CovidExternal::TA_SCM_COVID_EXT_WEEKLY_MODEL_TRAIN\""
				}
			},
			"name": "constantgenerator111"
		},
		"saphanaclient1111": {
			"component": "com.sap.hana.client2",
			"metadata": {
				"label": "EXTERNAL_MERGE_WEEKLY",
				"x": 201.99999904632568,
				"y": 132,
				"height": 80,
				"width": 120,
				"config": {
					"connection": {
						"configurationType": "Configuration Manager",
						"connectionID": "HANA"
					},
					"tableName": "\"SEP_COVIDEXT\".\"Z_SEP.AnalyticalModels.SCM.DemandForecasting.CovidExternal::TA_SCM_COVID_EXT_WEEKLY_MODEL_TRAIN\"",
					"csvHeader": "Ignore",
					"tableColumns": [
						{
							"name": "\"date\"",
							"type": "DATE"
						},
						{
							"name": "\"state\"",
							"type": "NVARCHAR",
							"size": 50
						},
						{
							"name": "\"state_initial\"",
							"type": "NVARCHAR",
							"size": 50
						},
						{
							"name": "\"AT_adj\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"food_cpi_nat_mth\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"snap_cost_st_mth\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"allbed_mean\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"confirmed_infections\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"deaths_mean\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"est_infections_mean\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"mobility_composite_wors\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"states_on_stay_home\"",
							"type": "INTEGER"
						},
						{
							"name": "\"states_on_travel_limit\"",
							"type": "INTEGER"
						},
						{
							"name": "\"states_on_any_business\"",
							"type": "INTEGER"
						},
						{
							"name": "\"states_on_all_non-ess_business\"",
							"type": "INTEGER"
						},
						{
							"name": "\"states_on_any_gathering_restrict\"",
							"type": "INTEGER"
						},
						{
							"name": "\"states_on_educational_fac\"",
							"type": "INTEGER"
						}
					]
				}
			},
			"name": "saphanaclient111"
		},
		"tostringconverter111": {
			"component": "com.sap.util.toStringConverter",
			"metadata": {
				"label": "ToString Converter",
				"x": 386.99999809265137,
				"y": 132,
				"height": 50,
				"width": 50,
				"config": {}
			},
			"name": "tostringconverter11"
		},
		"saphanaclient121": {
			"component": "com.sap.hana.client2",
			"metadata": {
				"label": "SAP HANA Client",
				"x": 732.9999942779541,
				"y": 212,
				"height": 80,
				"width": 120,
				"config": {
					"connection": {
						"configurationType": "Configuration Manager",
						"connectionID": "HANA"
					},
					"tableName": "\"SEP_COVIDEXT\".\"TA_SCM_COVID_LONGTERM_FORECAST_OUTPUT_V1\"",
					"tableColumns": [
						{
							"name": "\"Index\"",
							"type": "INTEGER"
						},
						{
							"name": "\"retailer\"",
							"type": "NVARCHAR",
							"size": 100
						},
						{
							"name": "\"state\"",
							"type": "NVARCHAR",
							"size": 50
						},
						{
							"name": "\"brand\"",
							"type": "NVARCHAR",
							"size": 100
						},
						{
							"name": "\"ppg\"",
							"type": "NVARCHAR",
							"size": 100
						},
						{
							"name": "\"food_cpi_nat_mth\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"snap_cost_st_mth\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"week_ending_date\"",
							"type": "NVARCHAR",
							"size": 300
						},
						{
							"name": "\"FillMean\"",
							"type": "DOUBLE"
						}
					],
					"initTable": "None",
					"csvHeader": "Ignore"
				}
			},
			"name": "saphanaclient12"
		}
	},
	"groups": [
		{
			"name": "group4",
			"nodes": [
				"testscript1"
			],
			"metadata": {
				"description": "Group"
			},
			"tags": {
				"CP": ""
			},
			"multiplicity": 4
		}
	],
	"connections": [
		{
			"metadata": {
				"points": "701.9999961853027,102 768,102 768,52 833.9999942779541,52"
			},
			"src": {
				"port": "output",
				"process": "testscript1"
			},
			"tgt": {
				"port": "in1",
				"process": "terminal1"
			}
		},
		{
			"metadata": {
				"points": "701.9999961853027,120 768,120 768,172 833.9999942779541,172"
			},
			"src": {
				"port": "output2",
				"process": "testscript1"
			},
			"tgt": {
				"port": "input",
				"process": "python3operator1"
			}
		},
		{
			"metadata": {
				"points": "962.9999942779541,172 990.999993801117,172 990.999993801117,112 1018.9999933242798,112"
			},
			"src": {
				"port": "output",
				"process": "python3operator1"
			},
			"tgt": {
				"port": "stop",
				"process": "graphterminator1"
			}
		},
		{
			"metadata": {
				"points": "141,52 168.99999952316284,52 168.99999952316284,43 196.99999904632568,43"
			},
			"src": {
				"port": "out",
				"process": "constantgenerator111"
			},
			"tgt": {
				"port": "sql",
				"process": "saphanaclient111"
			}
		},
		{
			"metadata": {
				"points": "325.9999990463257,52 353.9999985694885,52 353.9999985694885,58 381.99999809265137,58"
			},
			"src": {
				"port": "result",
				"process": "saphanaclient111"
			},
			"tgt": {
				"port": "ininterface",
				"process": "tostringconverter11"
			}
		},
		{
			"metadata": {
				"points": "440.99999809265137,67 468.9999976158142,67 468.9999976158142,114.5 544.9999966621399,114.5 544.9999966621399,111 572.9999961853027,111"
			},
			"src": {
				"port": "outstring",
				"process": "tostringconverter11"
			},
			"tgt": {
				"port": "input1",
				"process": "testscript1"
			}
		},
		{
			"metadata": {
				"points": "141,172 168.99999952316284,172 168.99999952316284,163 196.99999904632568,163"
			},
			"src": {
				"port": "out",
				"process": "constantgenerator1111"
			},
			"tgt": {
				"port": "sql",
				"process": "saphanaclient1111"
			}
		},
		{
			"metadata": {
				"points": "325.9999990463257,172 353.9999985694885,172 353.9999985694885,148 381.99999809265137,148"
			},
			"src": {
				"port": "result",
				"process": "saphanaclient1111"
			},
			"tgt": {
				"port": "ininterface",
				"process": "tostringconverter111"
			}
		},
		{
			"metadata": {
				"points": "440.99999809265137,157 468.9999976158142,157 468.9999976158142,125.5 544.9999966621399,125.5 544.9999966621399,129 572.9999961853027,129"
			},
			"src": {
				"port": "outstring",
				"process": "tostringconverter111"
			},
			"tgt": {
				"port": "input2",
				"process": "testscript1"
			}
		},
		{
			"metadata": {
				"points": "701.9999961853027,138 715,138 715,261 727.9999942779541,261"
			},
			"src": {
				"port": "output3",
				"process": "testscript1"
			},
			"tgt": {
				"port": "data",
				"process": "saphanaclient121"
			}
		}
	],
	"inports": {},
	"outports": {}
}