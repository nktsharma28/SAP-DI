{
	"properties": {},
	"description": "RUN HANA SQL",
	"processes": {
		"python3operator11": {
			"component": "com.sap.system.python3Operator",
			"metadata": {
				"label": "Python36 - Inference",
				"x": 425.9999942779541,
				"y": 149,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {
					"metadata": {},
					"script": "\n\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.cluster import AgglomerativeClustering\nimport pickle\nimport io\n\ndef on_input(message):\n    \n    if(message.body and message.attributes['table']):\n        #Column names are hardcoded because of column tables don't match exactly names used on the script below\n        df = pd.DataFrame(message.body, columns=['CUSTOMER_ID','PROD_ECOLOGICAL', 'PROD_MEAT_SUBST', 'PROD_FAIRTRADE','PROD_REFORM', 'GREEN_ENERGY', 'FREQUENTING_NATURE', 'ENVIR_CHARITY','NATURE_CHARITY'\n                                                 ,'AGE_GROUP','EDUCATION','INCOME_LEVEL','TOTAL_USAGE_YEAR1', 'TOTAL_USAGE_YEAR2','ENERGY_SAVING','COST_TO_SERVE','HAS_EV','HAS_PV','RATE_ID',\n                                                  'RATE_DESCRIPTION'])\n        #api.send(\"output\", str(len(df.index)))\n    else:\n        return\n     # Input data\n    #df= pd.read_csv(\"/vrep/vflow/OFFER_PROPENSITY_INPUT.csv\")\n    #df =  pd.read_json(io.StringIO(msg))\n    #df= pd.read_csv(io.StringIO(msg.body), sep=\",\")\n    # Generic Columns Name\n    customer_id_col='CUSTOMER_ID'\n    survey_cols_to_summarize=['PROD_ECOLOGICAL', 'PROD_MEAT_SUBST', 'PROD_FAIRTRADE','PROD_REFORM', 'GREEN_ENERGY', 'FREQUENTING_NATURE', 'ENVIR_CHARITY','NATURE_CHARITY']\n    lifestyle_categorical_cols=['EDUCATION','INCOME_LEVEL']\n    lifestyle_numerical_cols=[]\n    energy_usage_cols=['TOTAL_USAGE_YEAR1', 'TOTAL_USAGE_YEAR2']\n    customer_engagement_numerical_cols=['ENERGY_SAVING','COST_TO_SERVE']\n    customer_engagement_categorical_cols=[]\n    df['NUMBER_OF_QUESTIONS_ANSWERED_YES']=df[survey_cols_to_summarize].sum(axis=1)\n    #api.send(\"output\",str(df.dtypes))\n    df['NUMBER_OF_QUESTIONS_ANSWERED_CAT'] = 'TWO OR THREE'\n    df.loc[df['NUMBER_OF_QUESTIONS_ANSWERED_YES']<=1, 'NUMBER_OF_QUESTIONS_ANSWERED_CAT'] = 'ONE OR LESS'\n    df.loc[df['NUMBER_OF_QUESTIONS_ANSWERED_YES']>=4, 'NUMBER_OF_QUESTIONS_ANSWERED_CAT'] = 'FOUR OR MORE'\n    # add the variable to list of categorical variables\n    lifestyle_categorical_cols.append('NUMBER_OF_QUESTIONS_ANSWERED_CAT')\n    df['ENERGY_SAVING']=df[energy_usage_cols].apply(lambda row: (row.iloc[1]-row.iloc[0])/row.iloc[0]*100, axis=1)\n    user_inputs_dict = {'customer_id' : customer_id_col, 'survey_cols_to_summarize' : survey_cols_to_summarize, 'energy_usage_cols' : energy_usage_cols}\n    #Score the new data\n    X = df[['CUSTOMER_ID', 'PROD_ECOLOGICAL', 'PROD_MEAT_SUBST', 'PROD_FAIRTRADE',\n           'PROD_REFORM', 'GREEN_ENERGY', 'FREQUENTING_NATURE', 'ENVIR_CHARITY',\n           'NATURE_CHARITY', 'AGE_GROUP', 'INCOME_LEVEL', 'EDUCATION',\n           'TOTAL_USAGE_YEAR1', 'TOTAL_USAGE_YEAR2', 'ENERGY_SAVING',\n           'COST_TO_SERVE', 'NUMBER_OF_QUESTIONS_ANSWERED_YES',\n           'NUMBER_OF_QUESTIONS_ANSWERED_CAT']]\n    categorical_transformer = Pipeline(steps=[('impute_missing', SimpleImputer(strategy='constant', fill_value='Other')), ('dummy_vars', OneHotEncoder(handle_unknown='ignore'))])\n    numeric_transformer = Pipeline(steps=[('impute_missing', SimpleImputer(strategy='mean')), ('standardise_vars', MinMaxScaler())])\n    lifestyle_preprocessor = ColumnTransformer(transformers=[\n        ('num', numeric_transformer, lifestyle_numerical_cols),\n        ('cat', categorical_transformer, lifestyle_categorical_cols)\n            ],sparse_threshold=0)\n            \n    lifestyle_postprocess = lifestyle_preprocessor.fit_transform(df)\n    lifestyle_cluster = AgglomerativeClustering(n_clusters = 3, affinity = 'manhattan', linkage ='complete')\n    y_clusters = lifestyle_cluster.fit_predict(lifestyle_postprocess)\n    df['LIFESTYLE_CLUSTER'] = y_clusters\n    df['LIFESTYLE_CLUSTER'] = df['LIFESTYLE_CLUSTER'] + 1\n    #loaded_model = pickle.load(open(\"lifestyle_clf.pickle.dat\", \"rb\"))\n    #df['LIFESTYLE_CLUSTER'] = loaded_model.predict(X)\n    df['Q1_ENERGY_SAVING'] = df['ENERGY_SAVING'].quantile(0.25)\n    df['Q3_ENERGY_SAVING'] = df['ENERGY_SAVING'].quantile(0.75)\n    df['Q1_COST_TO_SERVE'] = df['COST_TO_SERVE'].quantile(0.25)\n    df['Q3_COST_TO_SERVE'] = df['COST_TO_SERVE'].quantile(0.75)\n    df['ENERGY_SAVING_CAT'] = np.where(df['ENERGY_SAVING']<=df['Q1_ENERGY_SAVING'],'LOW','MEDIUM')\n    df['ENERGY_SAVING_CAT'] = np.where(df['ENERGY_SAVING']>=df['Q3_ENERGY_SAVING'],'HIGH',df['ENERGY_SAVING_CAT'])\n    df['COST_TO_SERVE_CAT'] = np.where(df['COST_TO_SERVE']<=df['Q1_COST_TO_SERVE'],'LOW','MEDIUM')\n    df['COST_TO_SERVE_CAT'] = np.where(df['COST_TO_SERVE']>=df['Q3_COST_TO_SERVE'],'HIGH',df['ENERGY_SAVING_CAT'])\n\n    #Clusters\n    df['ENGAGEMENT_CLUSTER'] = np.where(((df['ENERGY_SAVING_CAT']=='MEDIUM')&(df['COST_TO_SERVE_CAT']=='HIGH')),'CLUSTER1','OTHER')\n    df['ENGAGEMENT_CLUSTER'] = np.where(((df['ENERGY_SAVING_CAT']=='MEDIUM')&(df['COST_TO_SERVE_CAT']=='LOW')),'CLUSTER2',df['ENGAGEMENT_CLUSTER'])\n    df['ENGAGEMENT_CLUSTER'] = np.where(((df['ENERGY_SAVING_CAT']=='HIGH')&((df['COST_TO_SERVE_CAT']=='MEDIUM')|(df['COST_TO_SERVE_CAT']=='HIGH'))),'CLUSTER3',df['ENGAGEMENT_CLUSTER'])\n    df['ENGAGEMENT_CLUSTER'] = np.where(((df['ENERGY_SAVING_CAT']=='LOW')&((df['COST_TO_SERVE_CAT']=='MEDIUM')|(df['COST_TO_SERVE_CAT']=='LOW'))),'CLUSTER4',df['ENGAGEMENT_CLUSTER'])\n    df['ENGAGEMENT_CLUSTER'] = np.where(((df['ENERGY_SAVING_CAT']=='HIGH')&(df['COST_TO_SERVE_CAT']=='LOW')),'CLUSTER5',df['ENGAGEMENT_CLUSTER'])\n    df['ENGAGEMENT_CLUSTER'] = np.where(((df['ENERGY_SAVING_CAT']=='LOW')&(df['COST_TO_SERVE_CAT']=='HIGH')),'CLUSTER6',df['ENGAGEMENT_CLUSTER'])\n    #Offer\n    df['OFFER'] = np.where((((df['ENGAGEMENT_CLUSTER']=='CLUSTER3')|(df['ENGAGEMENT_CLUSTER']=='CLUSTER5'))&(df['HAS_EV']==1)&(df['LIFESTYLE_CLUSTER']==2)),'OFFER1','NONE')\n    df['OFFER'] = np.where((((df['ENGAGEMENT_CLUSTER']=='CLUSTER3')|(df['ENGAGEMENT_CLUSTER']=='CLUSTER4'))&(df['LIFESTYLE_CLUSTER']==2)),'OFFER2',df['OFFER'])\n    df['OFFER'] = np.where(((df['ENGAGEMENT_CLUSTER']=='CLUSTER1')&((df['LIFESTYLE_CLUSTER']==2)|(df['LIFESTYLE_CLUSTER']==3))&((df['RATE_ID']==2)\n                                                                                                                               |(df['RATE_ID']==3)|(df['RATE_ID']==6)\n                                                                                                                               |(df['RATE_ID']==9)|(df['RATE_ID']==10)\n                                                                                                                               |(df['RATE_ID']==12)|(df['RATE_ID']==13)\n                                                                                                                               |(df['RATE_ID']==16))),'OFFER3',df['OFFER'])\n    df['OFFER'] = np.where(((df['ENGAGEMENT_CLUSTER']=='CLUSTER6')&((df['LIFESTYLE_CLUSTER']==2)|(df['LIFESTYLE_CLUSTER']==3))&((df['RATE_ID']==2)\n                                                                                                                               |(df['RATE_ID']==3)|(df['RATE_ID']==6)\n                                                                                                                               |(df['RATE_ID']==9)|(df['RATE_ID']==10)\n                                                                                                                               |(df['RATE_ID']==12)|(df['RATE_ID']==13)\n                                                                                                                               |(df['RATE_ID']==16))),'OFFER4',df['OFFER'])\n    df['OFFER'] = np.where((((df['ENGAGEMENT_CLUSTER']=='CLUSTER2')|(df['ENGAGEMENT_CLUSTER']=='CLUSTER5'))&(df['HAS_PV']==1)&(df['LIFESTYLE_CLUSTER']==2)),'OFFER5',df['OFFER'])\n    \n    df['OFFER_DESC']=''\n    selected_columns = df[['CUSTOMER_ID','PROD_ECOLOGICAL','PROD_MEAT_SUBST','PROD_FAIRTRADE','PROD_REFORM','GREEN_ENERGY'\n    ,'FREQUENTING_NATURE','ENVIR_CHARITY','NATURE_CHARITY','AGE_GROUP','INCOME_LEVEL','EDUCATION','TOTAL_USAGE_YEAR1','TOTAL_USAGE_YEAR2'\n    ,'ENERGY_SAVING','COST_TO_SERVE','NUMBER_OF_QUESTIONS_ANSWERED_YES','NUMBER_OF_QUESTIONS_ANSWERED_CAT'\n    ,'LIFESTYLE_CLUSTER','ENGAGEMENT_CLUSTER','HAS_EV','HAS_PV','RATE_ID','RATE_DESCRIPTION','OFFER','OFFER_DESC']]\n    df2 = selected_columns.copy()\n    #df.drop(['Q1_ENERGY_SAVING','Q3_ENERGY_SAVING','Q1_COST_TO_SERVE','Q3_COST_TO_SERVE','ENERGY_SAVING_CAT','COST_TO_SERVE_CAT'], axis = 1)\n    api.send(\"output\",df2.to_csv())\n    #api.send(\"output\",str(df2.dtypes))\n\n\n\napi.set_port_callback(\"input1\", on_input)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"\"\"\nimport json\n\n# Global vars to keep track of model status\nmodel = None\nmodel_ready = False\n\n# Validate input data is JSON\ndef is_json(data):\n  try:\n    json_object = json.loads(data)\n  except ValueError as e:\n    return False\n  return True\n\n# When Model Blob reaches the input port\ndef on_model(model_blob):\n    global model\n    global model_ready\n\n    model = model_blob\n    model_ready = True\n    api.logger.info(\"Model Received & Ready\")\n\n# Client POST request received\ndef on_input(msg):\n    error_message = \"\"\n    success = False\n    try:\n        api.logger.info(\"POST request received from Client - checking if model is ready\")\n        if model_ready:\n            api.logger.info(\"Model Ready\")\n            api.logger.info(\"Received data from client - validating json input\")\n            \n            user_data = msg.body.decode('utf-8')\n            # Received message from client, verify json data is valid\n            if is_json(user_data):\n                api.logger.info(\"Received valid json data from client - ready to use\")\n                \n                # apply your model\n                # obtain your results\n                success = True\n            else:\n                api.logger.info(\"Invalid JSON received from client - cannot apply model.\")\n                error_message = \"Invalid JSON provided in request: \" + user_data\n                success = False\n        else:\n            api.logger.info(\"Model has not yet reached the input port - try again.\")\n            error_message = \"Model has not yet reached the input port - try again.\"\n            success = False\n    except Exception as e:\n        api.logger.error(e)\n        error_message = \"An error occurred: \" + str(e)\n    \n    if success:\n        # apply carried out successfully, send a response to the user\n        msg.body = json.dumps({'Results': 'Model applied to input data successfully.'})\n    else:\n        msg.body = json.dumps({'Error': error_message})\n    \n    new_attributes = {'message.request.id': msg.attributes['message.request.id']}\n    msg.attributes =  new_attributes\n    api.send('output', msg)\n    \napi.set_port_callback(\"model\", on_model)\napi.set_port_callback(\"input\", on_input)\n\"\"\""
				},
				"additionalinports": [
					{
						"name": "model",
						"type": "blob"
					},
					{
						"name": "input",
						"type": "string"
					},
					{
						"name": "input1",
						"type": "message.table"
					}
				],
				"additionaloutports": [
					{
						"name": "output",
						"type": "message"
					}
				]
			},
			"name": "python3operator1"
		},
		"runhanasql1": {
			"component": "com.sap.hana.runSQL",
			"metadata": {
				"label": "Run HANA SQL",
				"x": 179,
				"y": 140,
				"height": 80,
				"width": 120,
				"config": {
					"connection": {
						"configurationType": "Configuration Manager",
						"connectionID": "HANA"
					}
				}
			}
		},
		"constantgenerator11111": {
			"component": "com.sap.util.constantGenerator",
			"metadata": {
				"label": "Constant Generator",
				"x": -7.000002861022949,
				"y": 140,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {
					"content": "select * FROM       \"SEP_UTILITY\".\"OFFER_PROPENSITY_INPUT\"",
					"counter": 0
				}
			},
			"name": "constantgenerator1111"
		},
		"saphanaclient11": {
			"component": "com.sap.hana.client2",
			"metadata": {
				"label": "SAP HANA Client",
				"x": 770.9999923706055,
				"y": 135,
				"height": 80,
				"width": 120,
				"config": {
					"connection": {
						"configurationType": "Configuration Manager",
						"connectionID": "HANA"
					},
					"tableName": "\"SEP_UTILITY\".\"OFFER_PROPENSITY_OUTPUT\"",
					"tableColumns": [
						{
							"name": "\"Index\"",
							"type": "BIGINT"
						},
						{
							"name": "\"CUSTOMER_ID\"",
							"type": "BIGINT"
						},
						{
							"name": "\"PROD_ECOLOGICAL\"",
							"type": "NVARCHAR",
							"size": 1
						},
						{
							"name": "\"PROD_MEAT_SUBST\"",
							"type": "NVARCHAR",
							"size": 1
						},
						{
							"name": "\"PROD_FAIRTRADE\"",
							"type": "NVARCHAR",
							"size": 1
						},
						{
							"name": "\"PROD_REFORM\"",
							"type": "NVARCHAR",
							"size": 1
						},
						{
							"name": "\"GREEN_ENERGY\"",
							"type": "NVARCHAR",
							"size": 1
						},
						{
							"name": "\"FREQUENTING_NATURE\"",
							"type": "NVARCHAR",
							"size": 1
						},
						{
							"name": "\"ENVIR_CHARITY\"",
							"type": "NVARCHAR",
							"size": 1
						},
						{
							"name": "\"NATURE_CHARITY\"",
							"type": "NVARCHAR",
							"size": 1
						},
						{
							"name": "\"AGE_GROUP\"",
							"type": "NVARCHAR",
							"size": 10
						},
						{
							"name": "\"INCOME_LEVEL\"",
							"type": "NVARCHAR",
							"size": 100
						},
						{
							"name": "\"EDUCATION\"",
							"type": "NVARCHAR",
							"size": 30
						},
						{
							"name": "\"TOTAL_USAGE_YEAR1\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"TOTAL_USAGE_YEAR2\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"ENERGY_SAVING\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"COST_TO_SERVE\"",
							"type": "DOUBLE"
						},
						{
							"name": "\"NUMBER_OF_QUESTIONS_ANSWERED_YES\"",
							"type": "INTEGER"
						},
						{
							"name": "\"NUMBER_OF_QUESTIONS_ANSWERED_CAT\"",
							"type": "NVARCHAR",
							"size": 200
						},
						{
							"name": "\"LIFESTYLE_CLUSTER\"",
							"type": "INTEGER"
						},
						{
							"name": "\"ENGAGEMENT_CLUSTER\"",
							"type": "NVARCHAR",
							"size": 10
						},
						{
							"name": "\"HAS_EV\"",
							"type": "NVARCHAR",
							"size": 1
						},
						{
							"name": "\"HAS_PV\"",
							"type": "NVARCHAR",
							"size": 1
						},
						{
							"name": "\"RATE_ID\"",
							"type": "INTEGER"
						},
						{
							"name": "\"RATE_DESCRIPTION\"",
							"type": "NVARCHAR",
							"size": 300
						},
						{
							"name": "\"OFFER\"",
							"type": "NVARCHAR",
							"size": 100
						},
						{
							"name": "\"OFFER_DESC\"",
							"type": "NVARCHAR",
							"size": 100
						}
					],
					"initTable": "Drop (Cascade)",
					"csvHeader": "Ignore"
				}
			},
			"name": "saphanaclient1"
		}
	},
	"groups": [
		{
			"name": "group1",
			"nodes": [
				"python3operator11"
			],
			"metadata": {
				"description": "Group"
			},
			"tags": {
				"scikit-learn": "0.22.2"
			}
		}
	],
	"connections": [
		{
			"metadata": {
				"points": "116.99999713897705,180 174,180"
			},
			"src": {
				"port": "out",
				"process": "constantgenerator11111"
			},
			"tgt": {
				"port": "input",
				"process": "runhanasql1"
			}
		},
		{
			"metadata": {
				"points": "303,171 362,171 362,207 420.9999942779541,207"
			},
			"src": {
				"port": "success",
				"process": "runhanasql1"
			},
			"tgt": {
				"port": "input1",
				"process": "python3operator11"
			}
		},
		{
			"metadata": {
				"points": "549.9999942779541,189 658,189 658,184 765.9999923706055,184"
			},
			"src": {
				"port": "output",
				"process": "python3operator11"
			},
			"tgt": {
				"port": "data",
				"process": "saphanaclient11"
			}
		}
	],
	"inports": {},
	"outports": {}
}