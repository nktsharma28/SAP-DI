{
	"properties": {},
	"icon": "",
	"description": "ML_PTM - Cognitive Price Model Consumer",
	"processes": {
		"python3operator11111": {
			"component": "com.sap.system.python3Operator",
			"metadata": {
				"label": "CongnitivePricing_Training",
				"x": 462.99999713897705,
				"y": 185,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {
					"script": "#import Libraries\n\nimport numpy as np\nimport pandas as pd\n#import xgboost as xgb\nfrom sklearn import tree\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom scipy.optimize import minimize_scalar\nimport io\nimport pickle\n\ndef on_model(model_cp):\n    global loaded_model\n    global model_ready\n\n    import pickle\n    loaded_model = pickle.loads(model_cp)\n    \n    #model_ready = True\n    #api.logger.info(\"Model Received & Ready\")\n    #api.send(\"logging\", \"Model Ready!\")\n\ndef on_input(msg1, msg2):\n    \n    # Obtain data\n    # input table from Z_SEP.AnalyticalModels.LTO.IMC.CongnitivePricing::TA_IMC_CPQ_INFER_INPUT\n    \n    df_raw = pd.read_csv(io.StringIO(msg1.body), sep=\",\")\n    df = pd.DataFrame()\n    df['QUOTE_ID'] = df_raw.iloc[:,0]\n    df['CUSTOMER_NAME'] = df_raw.iloc[:,1]\n    df['INDUSTRY'] = df_raw.iloc[:,2]\n    df['CREATION_DATE'] = df_raw.iloc[:,3]\n    df['COUNTRY'] = df_raw.iloc[:,4]\n    df['PRODUCT_NAME'] = df_raw.iloc[:,5]\n    df['MODEL'] = df_raw.iloc[:,6]\n    df['SUPPLY_VOLTAGE_A'] = df_raw.iloc[:,7]\n    df['COM_QUANTITY'] = df_raw.iloc[:,8]\n    df['STATUS'] = df_raw.iloc[:,9]\n    df['LISTPRICE'] = df_raw.iloc[:,10].astype(float)\n    df['MANUFACTURING_COST'] = df_raw.iloc[:,11].astype(float)\n    df['QUOTED_PRICE'] = df_raw.iloc[:,12].astype(float) \n    \n   # input table from Z_SEP.AnalyticalModels.LTO.IMC.CongnitivePricing::TA_IMC_CPQ_INFER_INPUTTA_IMC_CPQ_TRAINING_SEGMENTS\n    Output_Seg_raw = pd.read_csv(io.StringIO(msg2.body), sep=\",\")\n    Output_Seg = pd.DataFrame()\n    Output_Seg['SEGMENT_ID'] = Output_Seg_raw.iloc[:,0].astype(int)\n    Output_Seg['LEAD_BRAND_ID'] = Output_Seg_raw.iloc[:,1].astype(int)\n    Output_Seg['LEADING_PRODUCT'] = Output_Seg_raw.iloc[:,2]\n    Output_Seg['COUNT'] = Output_Seg_raw.iloc[:,3].astype(float)\n    Output_Seg['VAL_SEG_ID'] = Output_Seg_raw.iloc[:,4].astype(int)\n    Output_Seg['VAL_MIN'] = Output_Seg_raw.iloc[:,5].astype(float)\n    Output_Seg['VAL_MAX'] = Output_Seg_raw.iloc[:,6].astype(float)\n    Output_Seg['VAL_COUNT'] = Output_Seg_raw.iloc[:,7].astype(float)\n    Output_Seg['LEAD_CONST'] = Output_Seg_raw.iloc[:,8].astype(float)\n    Output_Seg['LEAD_GP_PCT_VALUE'] = Output_Seg_raw.iloc[:,9].astype(float)\n    Output_Seg['LEAD_LIST_VALUE'] = Output_Seg_raw.iloc[:,10].astype(float)\n    Output_Seg['LEAD_TMC_VALUE'] = Output_Seg_raw.iloc[:,11].astype(float)\n    Output_Seg['VAL_CONST'] = Output_Seg_raw.iloc[:,12].astype(float)\n    Output_Seg['VAL_GP_PCT_VALUE'] = Output_Seg_raw.iloc[:,13].astype(float) \n    Output_Seg['VAL_LIST_VALUE'] = Output_Seg_raw.iloc[:,14].astype(float) \n    Output_Seg['VAL_TMC_VALUE'] = Output_Seg_raw.iloc[:,15].astype(float)  \n\n    def WProb_(x, input_coef, b):\n        \"\"\"\n        Given a price and parameters of the package compute the win probability\n        x: input price\n        input_coef: Series containing other input parameters of the package\n        b: Series containing the estimated parameters of the regression model\n        \"\"\"                                                                                                                                                                \n        #fill the NaN value with 0 for computation\n        b = b.fillna(0.0)  \n        listp_value = input_coef['LIST_VALUE'] - 1\n        tmc = input_coef['TMC'] \n        listp = input_coef['LISTPRICE']\n        value = listp / input_coef['LIST_VALUE']\n        tmc_value = 1 - tmc / value \n        regressor=[1.0, - (x - tmc) / value, listp_value, tmc_value]\n        z = np.exp(np.dot(regressor, b)) / ( 1 + np.exp(np.dot(regressor, b)) )\n        return z\n\n\n    def Rev_(x, input_coef, b):\n        \"\"\"\n        Given a price and parameters of the package compute the NEGATIVE revenue\n        x: input price\n        input_coef: Series containing other input parameters of the package\n        b: Series containing the estimated parameters of the regression model\n        \"\"\"     \n        tmc = input_coef['TMC']                                                                                                                                                            \n        return - (x - tmc) * WProb_(x, input_coef, b)    \n\n\n    def OptPrice(Input, b):\n        \"\"\"\n        Given the input and price sensitivity information compute optimal price\n        x: input price\n        Input: Dataframe containing all the input information\n        b: Series containing the estimated parameters of the regression model\n        \"\"\"   \n        Value = Input.LISTPRICE / Input.LIST_VALUE\n        TMC = Input.TMC\n        QuotePrice = Input.GP_PCT_VALUE * Value + Input.TMC\n        #Organizing Response variables\n        Response = Input['Win']        \n        #Creating Lists for storing results\n        WP_act = list(range(len(Response)))\n        gp_pct_act = list(range(len(Response)))\n        Discount_act = list(range(len(Response)))\n        WP_opt = list(range(len(Response)))\n        gp_pct_opt = list(range(len(Response)))\n        OptPrice = list(range(len(Response)))\n        Discount_opt = list(range(len(Response)))\n\n        for i in range(len(Response)):\n            input_coef = Input.iloc[i]  \n            x_act = QuotePrice.iloc[i]\n            c = TMC.iloc[i]  \n            p_l = Input.LISTPRICE.iloc[i]    \n            WP_act[i] = WProb_(x_act, input_coef, b)\n            gp_pct_act[i] = (x_act - c) / x_act \n            Discount_act[i] = (p_l - x_act) / p_l\n\n            res = minimize_scalar(Rev_, bounds = (c, p_l), args = (input_coef, b), method = 'bounded') \n            x_opt = res.x\n            WP_opt[i] = WProb_(x_opt, input_coef, b)\n            gp_pct_opt[i] = (x_opt - c) / x_opt\n            OptPrice[i] = x_opt\n            Discount_opt[i] = (p_l - x_opt) / p_l\n\n\n        #Combining the outcomes\n        #Add columns discount_act and discount_opt\n\n        Output = pd.DataFrame({})\n        Output['Response'] = Response.values\n        Output['QuotePrice'] = QuotePrice.values\n        Output['WP_act'] = WP_act\n        Output['gp_pct_act'] = gp_pct_act\n        Output['Discount_act'] = Discount_act\n        Output['OptPrice'] = OptPrice\n        Output['WP_opt'] = WP_opt\n        Output['gp_pct_opt'] = gp_pct_opt\n        Output['Discount_opt'] = Discount_opt\n        return Output\n\n\n    def Business_Case(Output, re_output = False):\n        \"\"\"\n        Compute the business case as a control for choosing segmentation.\n        Output: the output from OptPrice, records the optimal prices, etc\n        re_output: whether return the table for the business case result\n        Return: returns the sum of business case values and if re_ouput is specified\n        to be true, also returns the table of each business case value.\n        \"\"\"    \n        Revenue_Diff = list(range(len(Output)))\n        for i in range(len(Output)):\n            p_opt = Output.OptPrice.iloc[i]\n            p_act = Output.QuotePrice.iloc[i]\n            q_opt = Output.WP_opt.iloc[i]\n            q_act = Output.WP_act.iloc[i]\n            if Output.Response.iloc[i] == 1:\n                if p_opt > p_act:\n                    Revenue_Diff[i] = q_opt/q_act * p_opt - p_act\n                else:\n                    Revenue_Diff[i] = p_opt - p_act\n            else:\n                if p_opt > p_act:\n                    Revenue_Diff[i] = 0.0\n                else:\n                    Revenue_Diff[i] = (1 - (1 - q_opt)/(1 - q_act)) * p_opt                \n        BC_Value = np.sum(Revenue_Diff)\n        Output['Business_Case'] = Revenue_Diff\n        if re_output == False:\n            return BC_Value\n        else:\n            return BC_Value, Output\n\n\n    def unique_arr(arr):\n        \"\"\"\n        Helper function to return the unique values in a ndarray.\n        np.unique() can only deal wiht 1-D array.\n        \"\"\"\n        arr = np.asarray(arr)\n        uniques = []\n        for i in range(len(arr)):\n            if list(arr[i]) not in uniques:\n                uniques.append(list(arr[i]))\n        return uniques\n    def Label_Seg(Input_Data, Infile_Data):                  \n        \"\"\"\n        Labels each transaction in the original data to the segment it belongs.\n\n        Parameters\n        ----------\n        Input_Data: A dataframe that contains all the original transaction data.\n        Input_Seg: A dataframe that contains the segmentation information for each OD cluster pair\n        f_name: The data directory and file names to write the file\n        version: The version of data and cluster level\n\n        Return\n        -------\n        The revised input data.\n\n        \"\"\"                                     \n        seg_id = list(np.zeros(len(Input_Data), dtype = 'i4'))\n        Discount_act = list(np.zeros(len(Input_Data)))\n        Discount_sd =list(np.zeros(len(Input_Data)))\n        lw = list(np.zeros(len(Input_Data)))\n        up = list(np.zeros(len(Input_Data)))\n\n\n        for i in range(len(Input_Data)):\n            brand = Input_Data.loc[i,'PRODUCT_BRAND']\n            Value = Input_Data.loc[i,'LIST_VALUE']\n\n\n\n\n            if len(Infile_Data) > 1:\n                for j in range(len(Infile_Data)):\n                    if ( (brand == Infile_Data.loc[j, 'PRODUCT_BRAND']) and\n                    (Value > Infile_Data.loc[j, 'VAL_MIN']) and (Value <= Infile_Data.loc[j, 'VAL_MAX'])   ):\n                        seg_id[i] = Infile_Data.loc[j, 'SEGMENT_ID']\n\n                        lw[i] = 0\n                        up[i]=0\n            else:\n                seg_id[i] = Infile_Data.loc[0, 'SEGMENT_ID']\n\n                lw[i] = 0\n                up[i] = 0\n        Input_Data['SEGMENT_ID'] = seg_id\n\n\n        return Input_Data      \n    def Compute_Opt_Price(Input_Data, Infile_Data):                  \n        \"\"\"\n        Compute the optimal price according to the features and the corresponding parameter estimates in\n        \"Input_Seg\" for each transaction in \"Input_Data\".\n\n        Parameters\n        ----------\n        Input_Data: A dataframe that contains all the original transaction data / new request for quotes\n        Input_Seg: A dataframe that contains the segmentation AND regression information (FINAL_REG_SEG)\n        f_name: The data directory and file names to write the file\n\n\n        Outputs:\n        --------\n        Writes the labeled data to a new file.\n\n        Return\n        -------\n        The revised input data.\n\n        \"\"\"    \n        opt_price = list(np.zeros(len(Input_Data)))\n        x_opt = list(np.zeros(len(Input_Data))) \n        WP_act = list(np.zeros(len(Input_Data)))\n        WP_opt = list(np.zeros(len(Input_Data)))\n\n\n\n        for i in np.arange(len(Input_Data)):\n            if i % 1000 == 0:\n                print ('Processing quotes.')\n\n            seg_id = Input_Data.loc[i, 'SEGMENT_ID']\n            k = Input_Data.loc[i, 'TMC']\n            l = Input_Data.loc[i, 'LISTPRICE']\n            param = Infile_Data.loc[seg_id, ['VAL_const', 'VAL_GP_PCT_VALUE', 'VAL_LIST_VALUE','VAL_TMC_VALUE']]\n            param = param.fillna(0.0)\n            input_coef = Input_Data.iloc[i]\n\n            res1 = minimize_scalar( Rev_, bounds = (k,l), args = (input_coef, param), method = 'bounded' )\n\n\n            opt_price[i] = res1.x\n            x_opt[i] = opt_price[i]\n            x_act = Input_Data.loc[i, 'QUOTED_PRICE']\n            WP_act[i] = WProb_(x_act, input_coef, param)\n            WP_opt[i] = WProb_(x_opt[i], input_coef, param)\n\n\n\n        Input_Data['OPT_PRICE'] = opt_price\n        Input_Data['WIN_ACT'] = WP_act\n        Input_Data['WIN_OPT'] = WP_opt\n\n        return Input_Data\n\n\n\n    #Input Data -- \n    #test_data = pd.read_csv(\"C:/CogPrice/test_data.csv\")\n\n\n    # Developed model saved it in my local-- need some place to save it in DI\n    #loaded_model = pickle.load(open(\"xgb.pickle.dat\", \"rb\"))\n    \n    test_data = df\n    \n    X = pd.DataFrame(test_data, columns=['LISTPRICE','MANUFACTURING_COST'])\n    test_data['UtilityAdj'] = loaded_model.predict(X)\n  \n    test_data['LIST_VALUE'] = test_data['LISTPRICE']/test_data['UtilityAdj']\n    test_data['GP_PCT_VALUE'] = (test_data['QUOTED_PRICE'] - test_data['MANUFACTURING_COST'])/test_data['UtilityAdj']\n    test_data['GP_PCT_PRICE'] = (test_data['QUOTED_PRICE'] - test_data['MANUFACTURING_COST'])/test_data['QUOTED_PRICE']\n    test_data['Discount'] = 1-(test_data['QUOTED_PRICE']/test_data['LISTPRICE'])\n    test_data['PRODUCT_BRAND'] = test_data['MODEL']\n    test_data['TMC']= test_data['MANUFACTURING_COST']\n    test_data['Win']= np.where(test_data['STATUS'] == 'Y',1,0)\n\n    # This is the output segments ,should come from HANA table\n\n    test_data1 = Label_Seg(test_data, Output_Seg)\n    final_Output = Compute_Opt_Price(test_data1, Output_Seg)\n\n    discount_data = pd.DataFrame(final_Output,columns=['PRODUCT_BRAND','Discount']).copy()\n\n    discount_data['Discount_mean']=discount_data['Discount']\n    discount_data['Discount_std']=discount_data['Discount']\n    discount_agg_model = discount_data.groupby('PRODUCT_BRAND').agg({'Discount_mean':np.mean,'Discount_std':np.std}).reset_index()\n    del discount_data['Discount_mean']\n    del discount_data['Discount_std']\n    final_data = pd.merge(final_Output,discount_agg_model,on='PRODUCT_BRAND',how='left')\n    final_data['key1'] = 0\n    final_data['key2'] = 1\n    final_data['low']= 1-final_data['Discount_mean']- 2*final_data['Discount_std']\n    final_data['min_level'] = (final_data[['key2','low']]).min(axis=1)\n    final_data['max_min_level']=final_data[['min_level','key1']].max(axis=1)\n    final_data['low_bound'] = final_data['max_min_level']*final_data['LISTPRICE']\n\n    final_data['up']= 1-final_data['Discount_mean']+2*final_data['Discount_std']\n    final_data['min_level_up'] = (final_data[['key2','up']]).min(axis=1)\n    final_data['max_min_level_up']=final_data[['min_level_up','key1']].max(axis=1)\n    final_data['up_bound'] = final_data['max_min_level_up']*final_data['LISTPRICE']\n    final_data['low_bound'] =np.where(final_data['low_bound']<final_data['TMC'],final_data['TMC'],final_data['low_bound'])\n    final_data['up_bound'] =np.where(final_data['up_bound']<final_data['OPT_PRICE'],final_data['LISTPRICE'],final_data['up_bound'])\n\n    \n    fin_infer_opt_price = pd.DataFrame({ 'QUOTE_ID': final_data['QUOTE_ID'] ,'CUSTOMER_NAME':  final_data['CUSTOMER_NAME'],\n                              'INDUSTRY': final_data['INDUSTRY'], 'CREATION_DATE': final_data['CREATION_DATE'],\n                              'COUNTRY': final_data['COUNTRY'], 'QUANTITY': final_data['COM_QUANTITY'],\n                              'LISTPRICE': final_data['LISTPRICE'],'MANUFACTURING_COST': final_data['MANUFACTURING_COST'],\n                              'QUOTED_PRICE': final_data['QUOTED_PRICE'],'OPTIMUM_PRICE': final_data['OPT_PRICE'],\n                              'PROB_WIN_OPTIMAL':final_data['WIN_OPT'],'PROB_WIN_ACTUAL': final_data['WIN_ACT'],\n                              'OPTIMAL_LOWER':final_data['low_bound'],'OPTIMAL_HIGHER':final_data['up_bound'],})\n    \n    fin_infer_opt_price.fillna(0, inplace=True)\n    fin_infer_opt_price = fin_infer_opt_price.round(6)\n    \n    data =  fin_infer_opt_price.values.tolist()\n    api.send(\"output1\",data)\n    #data2 = [fin_Output_Seg.columns.values.tolist()] + Output_Seg.values.tolist()\n    f = '{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}'  # format final_data\n    #f2 = '{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}' # format Output_Seg\n    #for i in data:\n        #api.send(\"output1\",f.format(*i)+'\\n')\n    \n    \n#fin_infer_opt_price write-back to Hana Output Table \"TA_IMC_CPQ_INFER_OPTIMAL_PRICE\"\n\n\napi.set_port_callback(\"model\", on_model)\napi.set_port_callback([\"input2\",\"input2\"], on_input)"
				},
				"additionalinports": [
					{
						"name": "input2",
						"type": "message"
					},
					{
						"name": "input1",
						"type": "message"
					},
					{
						"name": "model",
						"type": "blob"
					}
				],
				"additionaloutports": [
					{
						"name": "output1",
						"type": "message"
					}
				]
			},
			"name": "python3operator1111"
		},
		"constantgenerator1": {
			"component": "com.sap.util.constantGenerator",
			"metadata": {
				"label": "Submit Artifact Name",
				"x": 17,
				"y": 252,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {
					"content": "${ARTIFACT:MODEL}"
				}
			}
		},
		"artifactconsumer1": {
			"component": "com.sap.ml.artifact.consumer",
			"metadata": {
				"label": "Artifact Consumer",
				"x": 201.99999904632568,
				"y": 222,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {
					"opMode": "input"
				}
			}
		},
		"wiretap11": {
			"component": "com.sap.util.wiretap",
			"metadata": {
				"label": "Wiretap",
				"x": 667.9999961853027,
				"y": 177,
				"height": 80,
				"width": 120,
				"ui": "dynpath",
				"config": {}
			},
			"name": "wiretap1"
		},
		"readfile1111": {
			"component": "com.sap.file.read",
			"metadata": {
				"label": "Read File",
				"x": 17,
				"y": 132,
				"height": 80,
				"width": 120,
				"config": {
					"mode": "Once",
					"connection": {
						"configurationType": "Connection Management",
						"connectionID": "DI_DATA_LAKE"
					},
					"path": "/shared/TEST_INFER_INPUT.csv"
				}
			},
			"name": "readfile111"
		},
		"tostringconverter1111": {
			"component": "com.sap.util.toStringConverter",
			"metadata": {
				"label": "ToString Converter",
				"x": 226.5,
				"y": 131,
				"height": 50,
				"width": 50,
				"config": {}
			},
			"name": "tostringconverter111"
		},
		"readfile11111": {
			"component": "com.sap.file.read",
			"metadata": {
				"label": "Read File",
				"x": 17,
				"y": 12,
				"height": 80,
				"width": 120,
				"config": {
					"mode": "Once",
					"connection": {
						"configurationType": "Connection Management",
						"connectionID": "DI_DATA_LAKE"
					},
					"path": "/shared/TEST_TRAINING_SEGMENT.csv"
				}
			},
			"name": "readfile1111"
		},
		"tostringconverter11111": {
			"component": "com.sap.util.toStringConverter",
			"metadata": {
				"label": "ToString Converter",
				"x": 277.4999990463257,
				"y": 27,
				"height": 50,
				"width": 50,
				"config": {}
			},
			"name": "tostringconverter1111"
		}
	},
	"groups": [
		{
			"name": "group11",
			"nodes": [
				"python3operator11111"
			],
			"metadata": {
				"description": "Group"
			},
			"tags": {
				"CP": ""
			}
		}
	],
	"connections": [
		{
			"metadata": {
				"points": "141,292 168.99999952316284,292 168.99999952316284,271 196.99999904632568,271"
			},
			"src": {
				"port": "out",
				"process": "constantgenerator1"
			},
			"tgt": {
				"port": "inArtifactID",
				"process": "artifactconsumer1"
			}
		},
		{
			"metadata": {
				"points": "586.999997138977,225 634.9999966621399,225 634.9999966621399,217 662.9999961853027,217"
			},
			"src": {
				"port": "output1",
				"process": "python3operator11111"
			},
			"tgt": {
				"port": "in",
				"process": "wiretap11"
			}
		},
		{
			"metadata": {
				"points": "141,43 272.4999990463257,43"
			},
			"src": {
				"port": "file",
				"process": "readfile11111"
			},
			"tgt": {
				"port": "ininterface",
				"process": "tostringconverter11111"
			}
		},
		{
			"metadata": {
				"points": "331.4999990463257,52 394.75,52 394.75,207 457.99999713897705,207"
			},
			"src": {
				"port": "outstring",
				"process": "tostringconverter11111"
			},
			"tgt": {
				"port": "input2",
				"process": "python3operator11111"
			}
		},
		{
			"metadata": {
				"points": "325.9999990463257,244 353.9999985694885,244 353.9999985694885,236 429.9999976158142,236 429.9999976158142,243 457.99999713897705,243"
			},
			"src": {
				"port": "outArtifact",
				"process": "artifactconsumer1"
			},
			"tgt": {
				"port": "model",
				"process": "python3operator11111"
			}
		},
		{
			"metadata": {
				"points": "141,163 181.25,163 181.25,147 221.5,147"
			},
			"src": {
				"port": "file",
				"process": "readfile1111"
			},
			"tgt": {
				"port": "ininterface",
				"process": "tostringconverter1111"
			}
		},
		{
			"metadata": {
				"points": "280.5,156 369.25,156 369.25,225 457.99999713897705,225"
			},
			"src": {
				"port": "outstring",
				"process": "tostringconverter1111"
			},
			"tgt": {
				"port": "input1",
				"process": "python3operator11111"
			}
		}
	],
	"inports": {},
	"outports": {}
}